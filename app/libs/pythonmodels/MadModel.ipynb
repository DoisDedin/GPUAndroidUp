{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaovitorcotta/StudioProjects/VulkanFFT/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MADModel(tf.Module):\n",
    "    @tf.function(input_signature=[tf.TensorSpec([4, None], tf.int32)])\n",
    "    def __call__(self, inputs):\n",
    "        # inputs: shape [4, N], dtype int32\n",
    "        timestamps = inputs[0]          # row 0: timestamps em ms\n",
    "        x = tf.cast(inputs[1], tf.float32)\n",
    "        y = tf.cast(inputs[2], tf.float32)\n",
    "        z = tf.cast(inputs[3], tf.float32)\n",
    "        # Magnitude vetorial\n",
    "        mag = tf.sqrt(x*x + y*y + z*z)\n",
    "        # √çndices de janela (cada 5s = 5000 ms)\n",
    "        win = tf.cast(tf.floor(tf.cast(timestamps, tf.float32) / 5000.0), tf.int32)\n",
    "        # Ajusta para come√ßar do zero (opcional)\n",
    "        min_win = tf.reduce_min(win)\n",
    "        win0 = win - min_win\n",
    "        # Soma e contagem por janela\n",
    "        num_wins = tf.reduce_max(win0) + 1\n",
    "        sums = tf.math.unsorted_segment_sum(mag, win0, num_wins)\n",
    "        counts = tf.math.unsorted_segment_sum(tf.ones_like(mag), win0, num_wins)\n",
    "        means = sums / counts  # pode gerar NaN onde count=0\n",
    "        valid = counts > 0\n",
    "        # N√∫mero de janelas n√£o vazias\n",
    "        num_valid = tf.reduce_sum(tf.cast(valid, tf.float32))\n",
    "        # Soma dos meios de janela v√°lidos e soma de seus quadrados\n",
    "        sum_means = tf.reduce_sum(tf.where(valid, means, tf.constant(0.0)))\n",
    "        sum_sq = tf.reduce_sum(tf.where(valid, means*means, tf.constant(0.0)))\n",
    "        # Estat√≠sticas finais\n",
    "        mean_of_means = sum_means / num_valid\n",
    "        mean_sq = sum_sq / num_valid\n",
    "        std_dev = tf.sqrt(mean_sq - mean_of_means*mean_of_means)\n",
    "        # m√≠nimo e m√°ximo ignorando slots inv√°lidos\n",
    "        safe_min = tf.where(valid, means, tf.constant(1e30))\n",
    "        safe_max = tf.where(valid, means, tf.constant(-1e30))\n",
    "        min_val = tf.reduce_min(safe_min)\n",
    "        max_val = tf.reduce_max(safe_max)\n",
    "        # Empacota sa√≠da [mean, std, min, max]\n",
    "        return tf.stack([mean_of_means, std_dev, min_val, max_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qv/p5h208kn6gd462qyk1_qdbh00000gn/T/tmpu8ip6n3e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qv/p5h208kn6gd462qyk1_qdbh00000gn/T/tmpu8ip6n3e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo modelo salvo com sucesso.\n",
      "Shape de entrada: [4 1]\n",
      "Shape signature : [ 4 -1]\n",
      "Tipo de entrada : <class 'numpy.int32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1750712531.828495 22855745 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1750712531.828515 22855745 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-06-23 18:02:11.829008: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/qv/p5h208kn6gd462qyk1_qdbh00000gn/T/tmpu8ip6n3e\n",
      "2025-06-23 18:02:11.829190: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-06-23 18:02:11.829194: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/qv/p5h208kn6gd462qyk1_qdbh00000gn/T/tmpu8ip6n3e\n",
      "I0000 00:00:1750712531.830538 22855745 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-06-23 18:02:11.830710: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-06-23 18:02:11.835012: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/qv/p5h208kn6gd462qyk1_qdbh00000gn/T/tmpu8ip6n3e\n",
      "2025-06-23 18:02:11.838477: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 9470 microseconds.\n",
      "2025-06-23 18:02:11.844411: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Caminho do modelo\n",
    "tflite_path = \"mad_model.tflite\"\n",
    "\n",
    "# Remove o modelo anterior, se existir\n",
    "if os.path.exists(tflite_path):\n",
    "    os.remove(tflite_path)\n",
    "    print(\"Modelo antigo removido.\")\n",
    "\n",
    "# Cria o modelo\n",
    "mad_model = MADModel()\n",
    "\n",
    "# Define a fun√ß√£o concreta explicitamente com shape din√¢mico\n",
    "concrete_fn = mad_model.__call__.get_concrete_function(\n",
    "    tf.TensorSpec(shape=[4, None], dtype=tf.int32)\n",
    ")\n",
    "\n",
    "# Converte para TFLite com suporte a operadores do TF\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
    "    [concrete_fn],\n",
    "    mad_model\n",
    ")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Salva o modelo\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "    print(\"Novo modelo salvo com sucesso.\")\n",
    "\n",
    "# Verifica se o modelo foi salvo corretamente\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# ‚úÖ Esperado: shape [4, -1]\n",
    "print(\"Shape de entrada:\", input_details[0]['shape'])\n",
    "print(\"Shape signature :\", input_details[0]['shape_signature'])\n",
    "print(\"Tipo de entrada :\", input_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refer√™ncia (Python):  [8.808858  0.1548964 8.493439  9.178185 ]\n",
      "Modelo TFLite      :  8.808857\n",
      "Erro absoluto      :  [9.5367432e-07 8.6539602e+00 3.1541824e-01 3.6932850e-01]\n",
      "\n",
      "‚è±Ô∏è Tempo CPU (Python):        48.635 ms\n",
      "üì¶ Tempo de carga TFLite:      1.834 ms\n",
      "‚ö° Tempo de infer√™ncia TFLite: 0.227 ms\n",
      "üìâ Redu√ß√£o de tempo (inference): 99.53%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Fun√ß√£o equivalente √† sua getMAD() em Python\n",
    "def get_mad_py(data):\n",
    "    timestamps = data[0]\n",
    "    magnitudes = np.sqrt(np.sum(np.square(data[1:]), axis=0))\n",
    "    magnitude_by_time = list(zip(timestamps, magnitudes))\n",
    "\n",
    "    window_size_ms = 5000  # 5 segundos\n",
    "    start_time = magnitude_by_time[0][0]\n",
    "    end_time = magnitude_by_time[-1][0]\n",
    "\n",
    "    block_avgs = []\n",
    "    current_start = start_time\n",
    "\n",
    "    while current_start <= end_time:\n",
    "        current_end = current_start + window_size_ms\n",
    "        values = [mag for ts, mag in magnitude_by_time if current_start <= ts < current_end]\n",
    "        if values:\n",
    "            block_avgs.append(np.mean(values))\n",
    "        current_start = current_end\n",
    "\n",
    "    mean = np.mean(block_avgs)\n",
    "    std_dev = np.std(block_avgs)\n",
    "    min_val = np.min(block_avgs)\n",
    "    max_val = np.max(block_avgs)\n",
    "\n",
    "    return np.array([mean, std_dev, min_val, max_val], dtype=np.float32)\n",
    "\n",
    "# Gera√ß√£o de dados simulados\n",
    "N = 10000\n",
    "timestamps = np.arange(N, dtype=np.int32) * 20\n",
    "x = np.random.randint(0, 10, N, dtype=np.int32)\n",
    "y = np.random.randint(0, 10, N, dtype=np.int32)\n",
    "z = np.random.randint(0, 10, N, dtype=np.int32)\n",
    "input_data = np.stack([timestamps, x, y, z], axis=0)  # shape [4, N]\n",
    "\n",
    "# --- TEMPO: fun√ß√£o Python pura ---\n",
    "start_cpu = time.time()\n",
    "mad_ref = get_mad_py(input_data)\n",
    "end_cpu = time.time()\n",
    "cpu_time_ms = (end_cpu - start_cpu) * 1000\n",
    "\n",
    "# --- TEMPO: carregamento do modelo TFLite ---\n",
    "start_load = time.time()\n",
    "interpreter = tf.lite.Interpreter(model_path=\"mad_model.tflite\")\n",
    "end_load = time.time()\n",
    "load_time_ms = (end_load - start_load) * 1000\n",
    "\n",
    "# Redimensiona entrada e aloca tensores\n",
    "N = input_data.shape[1]\n",
    "interpreter.resize_tensor_input(0, [4, N])\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# --- TEMPO: execu√ß√£o do modelo TFLite ---\n",
    "start_tflite = time.time()\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "mad_out = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "end_tflite = time.time()\n",
    "tflite_inference_time_ms = (end_tflite - start_tflite) * 1000\n",
    "\n",
    "# --- C√°lculo da redu√ß√£o de tempo ---\n",
    "reduction_pct = ((cpu_time_ms - tflite_inference_time_ms) / cpu_time_ms) * 100\n",
    "\n",
    "# --- Resultados ---\n",
    "print(\"Refer√™ncia (Python): \", mad_ref)\n",
    "print(\"Modelo TFLite      : \", mad_out)\n",
    "print(\"Erro absoluto      : \", np.abs(mad_ref - mad_out))\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Tempo CPU (Python):        {cpu_time_ms:.3f} ms\")\n",
    "print(f\"üì¶ Tempo de carga TFLite:      {load_time_ms:.3f} ms\")\n",
    "print(f\"‚ö° Tempo de infer√™ncia TFLite: {tflite_inference_time_ms:.3f} ms\")\n",
    "print(f\"üìâ Redu√ß√£o de tempo (inference): {reduction_pct:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
