2 Revisão bibliográfica

2.1 Computação em borda e dispositivos móveis

A computação em borda (edge computing) surge como evolução da computação em nuvem ao deslocar parte significativa do processamento para a periferia da rede, onde os dados são gerados. Em vez de enviar continuamente medições para servidores remotos, sensores inteligentes, smartphones e dispositivos vestíveis executam filtros, agregações e inferências localmente, reduzindo latência e tráfego de dados. Em aplicações de saúde conectada, segurança do trabalho e monitoramento de parâmetros fisiológicos, essa abordagem permite respostas imediatas a eventos críticos, mesmo em ambientes com conectividade intermitente. Smartphones e wearables, dotados de múltiplos sensores e unidades de processamento heterogêneas, tornaram-se plataformas privilegiadas para essa modalidade, pois combinam mobilidade, capacidade de comunicação e recursos computacionais suficientes para análises avançadas.

2.2 Processamento de sinais fisiológicos e séries temporais

Sinais provenientes de acelerômetros, fotopletismografia (PPG), eletrocardiograma (ECG) ou outros biossensores são séries temporais que refletem fenômenos dinâmicos do corpo humano. A análise desses dados exige técnicas que extraem características tanto no domínio do tempo quanto no domínio da frequência, permitindo detectar tendências, desvios e padrões repetitivos. Em monitoramento contínuo, é comum empregar pipelines que calculam métricas estatísticas, detectam eventos anômalos e transformam segmentos em representações espectrais capazes de alimentar classificadores ou sistemas de alerta. A consistência dessas características influencia diretamente a confiabilidade de diagnósticos remotos e de intervenções preventivas.

2.3 Mean Absolute Deviation (MAD) e estatísticas de janelas

O Mean Absolute Deviation é uma medida robusta de dispersão que quantifica o desvio médio absoluto de cada observação em relação à média. Em contextos de monitoramento em tempo real, calcular MAD e outras estatísticas (média, desvio padrão, valores mínimos e máximos) em janelas deslizantes permite identificar variações súbitas de amplitude ou estabilidade em sinais fisiológicos e vibracionais. Essa abordagem é particularmente útil quando se precisa distinguir atividades regulares de eventos fora do padrão, como quedas, tremores ou sobrecarga mecânica. O presente trabalho utiliza esse conjunto de métricas como bloco fundamental para avaliar os ganhos de desempenho ao executar o pipeline diretamente em dispositivos móveis.

2.4 Transformada Rápida de Fourier (FFT) em dispositivos embarcados

A Transformada Rápida de Fourier é o algoritmo de referência para converter sinais no domínio do tempo em representações espectrais, revelando componentes de frequência e harmonias relevantes para diagnóstico. Embora a FFT seja computacionalmente eficiente, sua execução em dispositivos embarcados impõe desafios relacionados à largura de banda de memória, à disponibilidade de unidades de ponto flutuante e às restrições energéticas típicas de plataformas móveis. O processamento em tempo real requer otimizações que reduzam cópias desnecessárias, explorem processamento paralelo e mantenham determinismo mesmo sob condições de energia variáveis. Esses fatores motivam a investigação de delegados e aceleradores que possam absorver parte da carga de trabalho sem comprometer a autonomia do dispositivo.

2.5 TensorFlow Lite e delegados (CPU, GPU, NNAPI)

O TensorFlow Lite é a vertente do TensorFlow voltada para inferência on-device, oferecendo interpretadores compactos e suporte a operadores otimizados. Sua arquitetura prevê o uso de delegados, que são módulos capazes de redirecionar partes do grafo de execução para unidades específicas, como CPU de alto desempenho, GPU móvel ou aceleradores expostos pelo Neural Networks API (NNAPI). Delegates CPU priorizam compatibilidade e facilidade de depuração; delegados GPU exploram paralelismo massivo para operações vetoriais; e o NNAPI serve como camada de abstração para NPUs ou DSPs disponíveis em determinados SoCs. Apesar desses benefícios, há limitações relevantes: o custo de transferir tensores entre memória do host e buffers dedicados pode dominar o tempo total, e a disponibilidade de operadores varia conforme o fabricante e a versão do sistema, exigindo avaliações caso a caso.

2.6 Trabalhos relacionados

Diversos autores ressaltam a necessidade de benchmarks sistemáticos para comparar o desempenho de modelos e operadores em TensorFlow Lite ao longo de diferentes gerações de smartphones, especialmente considerando redes neurais compactas e tarefas de detecção em tempo real. Há também estudos que mensuram o consumo de energia durante inferência on-device, analisando como o uso de GPU ou NNAPI influencia aquecimento e autonomia em cenários de uso contínuo. No campo de monitoramento fisiológico, trabalhos aplicados a mHealth, wearables e segurança ocupacional exploram métricas como MAD e FFT para caracterizar sinais e alimentar classificadores, embora muitas vezes tratem esses blocos de maneira superficial frente à ênfase em redes profundas. A presente pesquisa insere-se nesse contexto ao fornecer uma análise detalhada dessas operações fundamentais, evidenciando o comportamento dos delegates em situações representativas de computação em borda.

2.7 Granularidade de cálculo e mapeamento em TensorFlow Lite

Além da escolha dos algoritmos, o desempenho de sistemas de computação em borda depende da granularidade adotada para organizar os cálculos. Neste trabalho, granularidade é entendida em três dimensões principais: (i) o tamanho das janelas de dados, (ii) a quantidade de janelas processadas por chamada (lote) e (iii) o quanto da lógica de processamento é encapsulado dentro do grafo do TensorFlow Lite em oposição ao código nativo em CPU. A combinação dessas três dimensões determina se o custo fixo de preparação e transferência de tensores será amortizado ou se passará a dominar o tempo total de execução.

No nível temporal, a granularidade está associada ao comprimento das janelas enviadas a cada etapa. Janelas curtas favorecem alta responsividade, porém aumentam a razão entre custo fixo e custo útil de cálculo; janelas longas concentram mais operações por invocação, reduzindo o impacto relativo de inicializações e cópias. Neste estudo, as FFTs de 4 096, 8 192 e 16 384 amostras por sensor representam compromissos distintos entre resolução temporal, resolução espectral e eficiência computacional. O MAD segue a mesma lógica ao agrupar magnitudes em janelas de cinco segundos para extrair média, MAD, desvio padrão, mínimos e máximos.

A segunda dimensão refere-se ao batching, ou granularidade de lote. Ao agrupar diversas janelas em um único lote — como o modo x10 que processa doze pacotes consecutivos — o sistema paga o custo de transferência e preparação de buffers uma única vez, distribuindo-o por todas as janelas incluídas. Essa estratégia é crucial quando se empregam delegates do TensorFlow Lite, pois a comunicação entre o código nativo e o interpretador, além da movimentação de tensores para estruturas internas otimizadas, introduz um overhead quase constante por invocação. Lotes unitários tendem a ser dominados por esse custo, enquanto lotes maiores reduzem o tempo médio por janela e evidenciam o ganho relativo dos delegates.

A terceira dimensão aborda a granularidade do próprio grafo TFLite. Um modelo pode executar apenas a operação central — devolvendo intermediários para processamento na CPU — ou incorporar etapas adicionais de pré/pós-processamento (cálculo de magnitudes, normalizações, pesos dinâmicos e agregações estatísticas). Ao deslocar parte maior do pipeline para dentro do grafo reduzem-se as transferências intermediárias e o número de invocações, à custa de aumentar a complexidade do modelo e a dependência de operadores suportados pelo hardware. No projeto aqui descrito, o modelo de MAD encapsula o janelamento estatístico completo, enquanto o modelo de FFT abrange desde o RFFT até a aplicação de pesos dinâmicos, formando blocos autônomos de análise.

A noção de granularidade examinada neste capítulo generaliza-se para outros cálculos como convoluções, filtros digitais e transformadas tempo-frequência. Reorganizar operações em janelas e lotes de tamanhos distintos, bem como decidir quais etapas ficam dentro ou fora do grafo, influencia a relação entre custo de transferência e custo de processamento em qualquer pipeline de computação em borda. Assim, ainda que este TCC se concentre em MAD e FFT, as conclusões sobre a importância de granularidade fina versus granularidade grossa servem como guia para projetar sistemas que conciliem requisitos de latência, autonomia e fidelidade em dispositivos móveis.
