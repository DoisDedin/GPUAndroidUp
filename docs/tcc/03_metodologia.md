3 Metodologia

3.1 Tipo de pesquisa

Este trabalho caracteriza-se como uma pesquisa aplicada, de natureza quantitativa e com delineamento experimental. O foco recai sobre a avaliação empírica de pipelines de processamento estatístico e espectral em dispositivos Android, comparando o desempenho de implementações nativas em CPU com delegados do TensorFlow Lite (CPU, GPU e NNAPI). As execuções são conduzidas em condições controladas, com geração determinística de dados e repetição sistemática dos cenários, de modo a isolar os efeitos de transferência de memória, processamento e amortização por lotes, elementos centrais para sistemas de computação de borda orientados a sensores fisiológicos.

3.2 Ambiente de desenvolvimento

O aplicativo foi implementado em Kotlin sobre o Android Gradle Plugin 8.6.0, com suporte ao compilador Kotlin 1.9.0 e compatibilidade com JDK 17. A aplicação utiliza API 35 no momento de compilação, tem alvo em API 34 e exige API mínima 31, assegurando acesso às bibliotecas Jetpack mais recentes. O processamento numérico beneficia-se do TensorFlow Lite 2.16.1, incluindo as extensões para GPU e APIs específicas, além da biblioteca JTransforms 3.1 que serve como referência de FFT em CPU. O desenvolvimento ocorreu no Android Studio (versões Hedgehog/Koala) com Gradle 8.7 provido pelo wrapper. Para a geração e atualização dos modelos, adotou-se Python 3.9+ com TensorFlow 2.16, NumPy, SciPy, Matplotlib, Seaborn e Pandas em ambientes virtuais isolados. A etapa de experimentação foi realizada em três dispositivos físicos representativos de faixas distintas de hardware: Galaxy S21 (topo de linha com SoC Exynos 2100), Moto G84 5G (intermediário com Snapdragon 695) e Moto G04s (entrada com Spreadtrum T606), possibilitando analisar o impacto dos delegados em perfis de CPU/GPU e subsistemas de memória variados.

3.3 Modelos e funções avaliadas

Foram avaliados dois blocos funcionais. O primeiro corresponde ao cálculo de Mean Absolute Deviation (MAD) adaptado ao domínio de acelerômetros: o pipeline computa magnitudes tridimensionais, organiza janelas fixas de cinco segundos e extrai média, desvio padrão, mínimos e máximos a cada execução. Essa lógica está presente tanto na versão em Kotlin quanto no modelo TensorFlow Lite treinado em precisão FP32 para manter compatibilidade com CPU, GPU e NNAPI sem perdas de fidelidade. O segundo bloco implementa a Transformada Rápida de Fourier com pesos dinâmicos; nele, um modelo baseado em operações de RFFT processa simultaneamente dez sensores com comprimentos que variam de 512 a 65 536 pontos (limite adotado na interface) e gera magnitudes ponderadas. As versões experimentais de 128k, 256k e 524k pontos continuam disponíveis via scripts Python, mas foram desativadas na interface devido às falhas recorrentes de alocação observadas nos dispositivos de teste. Apesar de compartilharem o mesmo `.tflite`, os delegates GPU e NNAPI fazem fallback para XNNPACK porque o TensorFlow Lite ainda não oferece kernels FFT nesses backends; por isso toda a execução efetiva acontece no CPU, e as diferenças observadas entre delegates decorrem principalmente de cópias de buffer e ajustes de precisão (FP16/FP32) em cada driver. Ambos os modelos são construídos por scripts auxiliares em Python que replicam a lógica dos pipelines, exportam os artefatos TensorFlow Lite e os empacotam nos assets do aplicativo para consumo direto pelos interpretadores embarcados.

3.4 Arquitetura do sistema e integração com Android

A solução é organizada em dois módulos principais. A biblioteca de apoio concentra os geradores de lotes determinísticos de acelerômetro, construtores de tensores, processadores em CPU e wrappers de inferência TFLite, padronizando buffers diretos e medições de tempo. O módulo de aplicativo expõe a interface gráfica, ViewModel e serviços responsáveis por orquestrar execuções, acompanhar progresso e registrar resultados. O fluxo inicia com a geração dos lotes determinísticos, segue para o construtor de inputs (que prepara tensores reais, imaginários, magnitudes e pesos), passa pelo executor de benchmarks que decide o cenário e coleta tempos de transferência e processamento, e termina nos componentes de relato que gravam arquivos CSV e textos legíveis para benchmarks e testes energéticos. Todo o ciclo ocorre dentro do ecossistema Android, respeitando ciclos de vida de fragmentos, serviços em segundo plano e permissões de acesso ao armazenamento de arquivos de resultados.

3.5 Cenários de teste e métricas

Os cenários contemplam execuções individuais (single) e agregadas (x10) para MAD e FFT. Cada cenário foi repetido para **oito escalas** de dados (512, 1 024, 2 048, 4 096, 8 192, 16 384, 32 768 e 65 536 amostras por sensor), mantendo sempre dez sensores simultâneos no caso da FFT. As versões acima de 65 k existem apenas nos scripts auxiliares e foram marcadas como experimentais, pois nenhum dos dispositivos conseguiu completar os testes de 128k/256k/524k sem saturar a memória disponível. Essas combinações de tamanho de janela e de lote seguem o enquadramento de granularidade discutido na Seção 2.7, permitindo avaliar como diferentes níveis de agregação impactam o custo de transferência e o tempo de processamento. Os chips superiores da interface permitem selecionar o número de iterações por cenário e o tamanho do lote aplicado apenas aos modos x10; na campanha principal foram utilizados doze ciclos e lotes de doze pacotes consecutivos, o que possibilita calcular médias, desvios e limites com baixa variância. As métricas registradas incluem tempo total, tempos de transferência e processamento, desvio padrão, valores mínimo e máximo, throughput por amostra processada e indicadores de speedup quando comparado ao baseline em CPU. Notas textuais complementam cada linha com estatísticas de MAD ou resumos dos primeiros bins de FFT. O aplicativo também oferece um teste energético dedicado (quatro cenários MAD, cem execuções cada), mas nesta campanha os indicadores de energia/temperatura foram obtidos diretamente das medições anexadas a cada benchmark.

3.6 Procedimento experimental

O procedimento inicia configurando os chips de iteração e tamanho de lote conforme o plano experimental. Em seguida, para cada dispositivo, executa-se a suíte completa que percorre todos os cenários MAD e FFT nas versões single e x10, cobrindo as oito escalas válidas até 65 536 pontos. Em 09/12 cada botão foi pressionado cinco vezes seguidas (5 × 128 execuções) mantendo o gerador determinístico, o que resultou em 640 linhas por dispositivo (mais as linhas experimentais >64 k no Moto G84). Tentativas acima de 65 k são realizadas apenas quando o pesquisador habilita manualmente os scripts Python/CLI, uma vez que os dispositivos testados esgotam a RAM antes de concluir esses comprimentos. Os resultados são exportados automaticamente em arquivos CSV e textos resumidos por cenário. Após a coleta, scripts auxiliares processam os CSVs para gerar gráficos comparativos, tabelas e descrições em linguagem natural, além de consolidações multi-dispositivo. Essa rotina se repete para cada unidade de hardware, armazenando os artefatos em diretórios organizados por dispositivo e data, com um CSV consolidado para comparações cruzadas. O mesmo protocolo é seguido para o teste energético, garantindo que cada conjunto de execuções tenha logs completos e consistentes para análise quantitativa e discussão.
