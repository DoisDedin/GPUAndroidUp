3 Metodologia

3.1 Tipo de pesquisa

Este trabalho caracteriza-se como uma pesquisa aplicada, de natureza quantitativa e com delineamento experimental. O foco recai sobre a avaliação empírica de pipelines de processamento estatístico e espectral em dispositivos Android, comparando o desempenho de implementações nativas em CPU com delegados do TensorFlow Lite (CPU, GPU e NNAPI). As execuções são conduzidas em condições controladas, com geração determinística de dados e repetição sistemática dos cenários, de modo a isolar os efeitos de transferência de memória, processamento e amortização por lotes, elementos centrais para sistemas de computação de borda orientados a sensores fisiológicos.

3.2 Ambiente de desenvolvimento

O aplicativo foi implementado em Kotlin sobre o Android Gradle Plugin 8.6.0, com suporte ao compilador Kotlin 1.9.0 e compatibilidade com JDK 17. A aplicação utiliza API 35 no momento de compilação, tem alvo em API 34 e exige API mínima 31, assegurando acesso às bibliotecas Jetpack mais recentes. O processamento numérico beneficia-se do TensorFlow Lite 2.16.1, incluindo as extensões para GPU e APIs específicas, além da biblioteca JTransforms 3.1 que serve como referência de FFT em CPU. O desenvolvimento ocorreu no Android Studio (versões Hedgehog/Koala) com Gradle 8.7 provido pelo wrapper. Para a geração e atualização dos modelos, adotou-se Python 3.9+ com TensorFlow 2.16, NumPy, SciPy, Matplotlib, Seaborn e Pandas em ambientes virtuais isolados. A etapa de experimentação foi realizada em três dispositivos físicos representativos de faixas distintas de hardware: Galaxy S21 (topo de linha com SoC Exynos 2100), Moto G84 5G (intermediário com Snapdragon 695) e Moto G04s (entrada com Spreadtrum T606), possibilitando analisar o impacto dos delegados em perfis de CPU/GPU e subsistemas de memória variados.

3.3 Modelos e funções avaliadas

Foram avaliados dois blocos funcionais. O primeiro corresponde ao cálculo de Mean Absolute Deviation (MAD) adaptado ao domínio de acelerômetros: o pipeline computa magnitudes tridimensionais, organiza janelas fixas de cinco segundos e extrai média, desvio padrão, mínimos e máximos a cada execução. Essa lógica está presente tanto na versão em Kotlin quanto no modelo TensorFlow Lite treinado em precisão FP32 para manter compatibilidade com CPU, GPU e NNAPI sem perdas de fidelidade. O segundo bloco implementa a Transformada Rápida de Fourier com pesos dinâmicos; nele, um modelo baseado em operações de RFFT processa simultaneamente dez sensores com comprimentos de 4 096, 8 192 e 16 384 pontos, aplica normalizações opcionais e gera magnitudes ponderadas. Ambos os modelos são construídos por scripts auxiliares em Python que replicam a lógica dos pipelines, exportam os artefatos TensorFlow Lite e os empacotam nos assets do aplicativo para consumo direto pelos interpretadores embarcados.

3.4 Arquitetura do sistema e integração com Android

A solução é organizada em dois módulos principais. A biblioteca de apoio concentra os geradores de lotes determinísticos de acelerômetro, construtores de tensores, processadores em CPU e wrappers de inferência TFLite, padronizando buffers diretos e medições de tempo. O módulo de aplicativo expõe a interface gráfica, ViewModel e serviços responsáveis por orquestrar execuções, acompanhar progresso e registrar resultados. O fluxo inicia com a geração dos lotes determinísticos, segue para o construtor de inputs (que prepara tensores reais, imaginários, magnitudes e pesos), passa pelo executor de benchmarks que decide o cenário e coleta tempos de transferência e processamento, e termina nos componentes de relato que gravam arquivos CSV e textos legíveis para benchmarks e testes energéticos. Todo o ciclo ocorre dentro do ecossistema Android, respeitando ciclos de vida de fragmentos, serviços em segundo plano e permissões de acesso ao armazenamento de arquivos de resultados.

3.5 Cenários de teste e métricas

Os cenários contemplam execuções individuais (single) e agregadas (x10) para MAD e FFT. Cada cenário é repetido para três escalas de dados correspondentes a 4 096, 8 192 e 16 384 amostras por sensor, mantendo sempre dez sensores simultâneos no caso da FFT. Essas combinações de tamanho de janela e de lote seguem o enquadramento de granularidade discutido na Seção 2.7, permitindo avaliar como diferentes níveis de agregação impactam o custo de transferência e o tempo de processamento. Os chips superiores da interface permitem selecionar o número de iterações por cenário e o tamanho do lote aplicado apenas aos modos x10; na campanha principal foram utilizados doze ciclos e lotes de doze pacotes consecutivos, o que possibilita calcular médias, desvios e limites com baixa variância. As métricas registradas incluem tempo total, tempos de transferência e processamento, desvio padrão, valores mínimo e máximo, throughput por amostra processada e indicadores de speedup quando comparado ao baseline em CPU. Notas textuais complementam cada linha com estatísticas de MAD ou resumos dos primeiros bins de FFT. O teste energético acrescenta quatro cenários para MAD (CPU, TFLite CPU, TFLite GPU e TFLite NNAPI), cada um com cem execuções, e captura estado de bateria inicial/final, energia em nWh, carga em mAh, temperatura, se o dispositivo estava carregando e o status do modo de economia.

3.6 Procedimento experimental

O procedimento inicia configurando os chips de iteração e tamanho de lote conforme o plano experimental. Em seguida, para cada dispositivo, executa-se a suíte completa que percorre todos os cenários MAD e FFT nas versões single e x10, cobrindo as três escalas de dados. Os resultados são exportados automaticamente em arquivos CSV e textos resumidos por cenário. Após a coleta, scripts auxiliares processam os CSVs para gerar gráficos comparativos, tabelas e descrições em linguagem natural, além de consolidações multi-dispositivo. Essa rotina se repete para cada unidade de hardware, armazenando os artefatos em diretórios organizados por dispositivo e data, com um CSV consolidado para comparações cruzadas. O mesmo protocolo é seguido para o teste energético, garantindo que cada conjunto de execuções tenha logs completos e consistentes para análise quantitativa e discussão.
