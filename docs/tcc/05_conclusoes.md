5 Considerações finais

5.1 Síntese dos resultados

Este trabalho avaliou pipelines de Mean Absolute Deviation (MAD) e Transformada Rápida de Fourier (FFT) em dispositivos Android reais, confrontando implementações em CPU Kotlin com delegates do TensorFlow Lite (CPU, GPU e NNAPI) sob diferentes escalas de dados e configurações de lote. Os experimentos mostraram que, nas cargas de 4 096 e 16 384 pontos, os delegates TFLite proporcionaram ganhos consistentes em relação ao baseline nativo, principalmente quando o tamanho do vetor e o número de pacotes aumentam.

Para o MAD, os speedups variaram de aproximadamente 4× em dispositivos com CPUs mais potentes (Galaxy S21 e Moto G84 5G) até mais de 10× no Moto G04s, especialmente na escala 4× e nos modos x10. Na FFT, os ganhos foram moderados em aparelhos topo e intermediário (1,2× a 3×), mas chegaram a superar 10× no Moto G04s quando a GPU assumiu o processamento. A análise detalhada evidenciou que 70–85 % do tempo gasto pelos delegates está associado à transferência de dados para e dos buffers de inferência, o que limita a vantagem em cenários FFT e torna o delegate CPU quase tão eficiente quanto GPU ou NNAPI quando o gargalo se mantém inalterado. Também ficou claro que dispositivos de entrada colhem os maiores benefícios ao descarregar o cálculo para GPU ou para o backend TFLite, enquanto os modelos com CPUs mais robustas obtêm ganhos moderados, porém relevantes para reduzir latência e aquecimento. Em todos os casos, o processamento em lote (x10) reduziu o custo efetivo por pacote e elevou o throughput, confirmando a importância de amortizar o custo fixo de transferência ao projetar pipelines embarcados.

5.2 Limitações do estudo

Os resultados aqui apresentados refletem apenas três smartphones, o que restringe a generalização para outros perfis de hardware ou versões de sistema operacional. O escopo focou em duas operações de referência (MAD e FFT) e não abrangeu redes neurais completas ou modelos híbridos, ainda que essas operações apareçam em diversas arquiteturas de aprendizado. Além disso, os sinais utilizados foram gerados por um processo sintético baseado em acelerômetro; embora representem padrões realistas, não substituem a variabilidade de dados coletados em campo. Por fim, as métricas energéticas derivam de APIs do sistema e sensores internos, fornecendo estimativas consistentes mas não equivalentes a medições obtidas com equipamentos especializados, como monitores de corrente externos.

5.3 Trabalhos futuros

Como continuidade, recomenda-se expandir os experimentos para outras operações relevantes em computação em borda, incluindo convoluções, modelos completos em TensorFlow Lite e redes neurais voltadas a classificação de eventos. A incorporação de bibliotecas FFT especializadas, inclusive implementações otimizadas para GPU ou Vulkan, permitiria comparar abordagens e identificar eventuais vantagens sobre o delegate genérico. Também é desejável ampliar o conjunto de dispositivos testados, contemplando SoCs com NPUs dedicadas, perfis energéticos distintos e versões recentes do Android para observar como drivers e firmware impactam o desempenho. Finalmente, aplicar o pipeline a um caso real de monitoramento contínuo — em ambiente industrial ou de saúde — ajudará a validar o impacto das otimizações em sessões prolongadas e a correlacionar os ganhos de latência com melhorias concretas em usabilidade e autonomia.
